{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contact Center Insights\n",
    "\n",
    "This notebook demonstrates extracting valuable insights for contact centers using NVIDIA Riva and NVIDIA NIM microservices. \n",
    "\n",
    "Utilizing NVIDIA's Parakeet CTC 1.1b ASR model, it accurately transcribes audio interactions between two speakers. Subsequently, NVIDIA NIM Llama 3.3 70B processes the transcripts to extract key entities and evaluate agent performance, providing actionable insights to enhance contact center operations.\n",
    "\n",
    "Here is an architecture diagram of the workflow:\n",
    "\n",
    "![Contact Center Insights Architecture Diagram](./Architecture_Diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact Center Insights generation involves two steps:\n",
    "\n",
    "1. **Transcription with speaker Diarization**\n",
    "   - **NVIDIA Riva Integration:** Transcribes incoming audio calls between two speakers using NVIDIA Riva's Parakeet CTC 1.1b ASR model and creates a structured transcript.\n",
    "\n",
    "2. **Insight Generation**\n",
    "   - **Entity Extraction:** Extracts key entities like customer and agent names, topic and subtopic of the conversation.\n",
    "    - **Agent Performance Evaluation:** Evaluates agent performance based several key metrics.\n",
    "    - **Combine Insights:** Combines all extracted insights into a structured JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Overview\n",
    "1. [Install dependencies](#Install-dependencies)\n",
    "2. [Set required environment variables](#Set-required-environment-variables)\n",
    "3. [Transcribe Audio](#Transcribe-Audio)\n",
    "4. [Generate Insights](#Generate-Insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Set required environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "from pydub import AudioSegment\n",
    "import riva.client\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# validate we have the required variables\n",
    "REQUIRED_VARIABLES = [\n",
    "    \"NVIDIA_PARAKEET_NIM_API_KEY\",\n",
    "    \"NVIDIA_LLAMA_NIM_API_KEY\",\n",
    "]\n",
    "\n",
    "for var in REQUIRED_VARIABLES:\n",
    "    if var not in os.environ:\n",
    "        os.environ[var] = getpass.getpass(f\"Please set the {var} environment variable.\")\n",
    "\n",
    "# Check if there is an audio file in audio folder and get the file name\n",
    "audio_files = os.listdir(\"audio\")\n",
    "if len(audio_files) == 0:\n",
    "    raise Exception(\"No audio files found in the audio folder.\")\n",
    "    \n",
    "\n",
    "AUDIO_FILE = audio_files[0]\n",
    "print(f\"Using audio file: {AUDIO_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transcribe Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_audio_file(filename) -> BytesIO:\n",
    "    \"\"\"Return the audio file as a BytesIO object and convert it to mono channel.\"\"\"\n",
    "    \n",
    "    audio_segment = AudioSegment.from_file(f\"audio/{filename}\", format=\"wav\")\n",
    "    audio_segment = audio_segment.set_channels(1)\n",
    "\n",
    "    result_audio_bytes = BytesIO()\n",
    "    audio_segment.export(result_audio_bytes, format=\"wav\")\n",
    "\n",
    "    return result_audio_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_with_riva(audio_bytes)\n",
    "    NVIDIA_PARAKEET_NIM_API_KEY = os.environ[\"NVIDIA_PARAKEET_NIM_API_KEY\"]\n",
    "\n",
    "    # Initialize Riva ASR client\n",
    "    auth = riva.client.Auth(\n",
    "        uri=\"grpc.nvcf.nvidia.com\",  # Replace with your Riva server address\n",
    "        use_ssl=True,\n",
    "        metadata_args=[['authorization', 'Bearer ' + NVIDIA_PARAKEET_NIM_API_KEY],['function-id', '1598d209-5e27-4d3c-8079-4751568b1081']]\n",
    "    )\n",
    "\n",
    "    asr_client = riva.client.ASRService(auth)\n",
    "\n",
    "    # Audio file and configuration\n",
    "    config = riva.client.RecognitionConfig(\n",
    "        language_code=\"en-US\",\n",
    "        enable_word_time_offsets=True,  # Enables word timestamps\n",
    "        max_alternatives=1,  # Set to 1 for single-best result\n",
    "    )\n",
    "\n",
    "    # Transcribe the audio file\n",
    "    response = asr_client.offline_recognize(audio_bytes, config)\n",
    "\n",
    "    # Process and display transcription results with timestamps\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_bytes = prepare_audio_file(AUDIO_FILE)\n",
    "riva_response = transcribe_with_riva(audio_bytes.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert the response to a dialog like format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generate Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  Set up nvidia langchain with access to the llama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  Prompt llama 3.3 70B to generate entities - Agent name, Customer name, Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  Prompt llama 3.3 70B to generate agent performance metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
